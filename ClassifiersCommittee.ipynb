{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MachineNeyarning/ClassifiersCommittee/blob/main/ClassifiersCommittee.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comitê de Classificadores | Projeto N1\n",
        "\n",
        "**GitHub: https://github.com/MachineNeyarning/ClassifiersCommittee**\n",
        "\n",
        "---\n",
        "\n",
        "## Grupo:\n",
        "- Gustavo Henrique Martins\n",
        "- Ícaro Botelho\n",
        "- Maria Clara Seixa Scheffel\n",
        "- Maruan Biasi El Achkar\n",
        "- Ricardo Falcão Schlieper\n",
        "\n",
        "### Dataset escolhido: Rain in Australia\n",
        "- Detalhamento de colunas em: https://github.com/MachineNeyarning/ClassifiersCommittee/tree/main/dataset\n",
        "- Fonte: https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package\n",
        "- Target: RainTomorrow\n",
        "\n",
        "### Algoritmos escolhidos:\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- Decision Tree Classifier (Tree-Based)\n",
        "- Random Forest Classifier (Tree-Based)\n",
        "- LightGBM Classifier (Tree-Based)\n",
        "- CatBoost Classifier (Tree-Based)\n",
        "- Gaussian Naive Bayes (Naive Bayes)\n",
        "- Support Vector Classification (SVC)\n",
        "- Multi-Layer Perceptron (MLPClassifier)\n",
        "- AdaBoost Classifier (Ensemble Methods)\n",
        "- Quadratic Discriminant Analysis (QDA)\n",
        "\n"
      ],
      "metadata": {
        "id": "V58fMvJnRk_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Preparar Dataset"
      ],
      "metadata": {
        "id": "WH-an9SDiUwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixar Dataset\n",
        "\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "path = kagglehub.dataset_download(\"jsphyg/weather-dataset-rattle-package\")\n",
        "csv_path = os.path.join(path, 'weatherAUS.csv')\n"
      ],
      "metadata": {
        "id": "dcIR7kOZRhZh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e60c8db-7f1e-478e-d2c4-49fa1932fd8a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'weather-dataset-rattle-package' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar Dataframe Pandas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(csv_path, sep=',', engine='python', on_bad_lines='skip')\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "HaL6t3NUTGFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe Dataframe Data\n",
        "\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "chXUIEWjTn4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "432c3088"
      },
      "source": [
        "# Verificar falta de dados\n",
        "\n",
        "missing_data = df.isnull().sum()\n",
        "display(missing_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c539a59"
      },
      "source": [
        "# Remover linhas com dados faltando\n",
        "\n",
        "df_cleaned = df.dropna()\n",
        "display(df_cleaned.head())\n",
        "print(f\"Original: {df.shape}\")\n",
        "print(f\"Limpo: {df_cleaned.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# 12 Algoritimos:"
      ],
      "metadata": {
        "id": "e6-mCx6hUxif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 1) K-Nearest Neighbors (KNN) Falcão"
      ],
      "metadata": {
        "id": "hELrr__oYiZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_knn = df_cleaned"
      ],
      "metadata": {
        "id": "vA4p1py2Uu5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importar as Bibliotecas"
      ],
      "metadata": {
        "id": "JQF7gcpRo6I8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n"
      ],
      "metadata": {
        "id": "Fga8g9m4pRvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excluir a coluna 'Date' se não for relevante\n",
        "df_knn = df_knn.drop(columns=['Date'])\n",
        "\n",
        "# Converter variáveis categóricas em variáveis dummy (one-hot encoding)\n",
        "df_knn = pd.get_dummies(df_knn, drop_first=True)\n",
        "\n",
        "# Separar variáveis independentes (X) e dependentes (y)\n",
        "X = df_knn.drop(columns=['RainTomorrow_Yes'])  # Substitua 'PlayTennis_Yes' pelo nome da coluna alvo\n",
        "y = df_knn['RainTomorrow_Yes']"
      ],
      "metadata": {
        "id": "LSNnipOoINdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Escalar os dados\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Inicializar e treinar o modelo KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5) # Você pode ajustar o número de vizinhos\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Fazer previsões\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "# Avaliar o modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"KNN Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "id": "n29dUFq-rAHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2) Decision Tree Classifier (Tree-Based) | Gustavo"
      ],
      "metadata": {
        "id": "DZbTsFq5YoHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_dtc = df_cleaned"
      ],
      "metadata": {
        "id": "qs6AQn4sUw8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Decision Tree Classifier\n",
        "# ========================\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# features (X) e target (y)\n",
        "X = df_dtc.drop([\"RainTomorrow\", 'Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'], axis=1)  # variável alvo = \"RainTomorrow\"\n",
        "y = df_dtc[\"RainTomorrow\"]\n",
        "\n",
        "# converter TARGET para numerico\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# treino/teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# modelo e prediçoes\n",
        "dtc = DecisionTreeClassifier(random_state=42)\n",
        "dtc.fit(X_train, y_train)\n",
        "y_pred_dtc = dtc.predict(X_test)\n",
        "\n",
        "# métricas\n",
        "print(\"Decision Tree\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_dtc))\n",
        "print(confusion_matrix(y_test, y_pred_dtc))\n",
        "print(classification_report(y_test, y_pred_dtc))\n",
        "\n",
        "# ROC Curve\n",
        "y_prob_dtc = dtc.predict_proba(X_test)[:,1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_dtc)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label=f'Decision Tree (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Keep the plot code from the Random Forest cell to display all ROC curves together\n",
        "# plt.plot([0,1], [0,1], \"k--\")\n",
        "# plt.xlabel(\"False Positive Rate\")\n",
        "# plt.ylabel(\"True Positive Rate\")\n",
        "# plt.title(\"ROC Curve - Tree Based Models\")\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "-e3QnUJusCzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 3) Random Forest Classifier (Tree-Based) | Gustavo"
      ],
      "metadata": {
        "id": "PtlaUt1NYuO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_rfc = df_cleaned"
      ],
      "metadata": {
        "id": "Gb6Psgn0Uzca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Random Forest Classifier\n",
        "# ========================\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# features (X) e target (y)\n",
        "X = df_rfc.drop([\"RainTomorrow\", 'Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'], axis=1)\n",
        "y = df_rfc[\"RainTomorrow\"]\n",
        "\n",
        "# Convert TARGET to numeric\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# treino/teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# modelo e prediçoes\n",
        "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rfc = rfc.predict(X_test)\n",
        "\n",
        "# métricas\n",
        "print(\"Random Forest\")\n",
        "print(\"Acurácia:\", accuracy_score(y_test, y_pred_rfc))\n",
        "print(confusion_matrix(y_test, y_pred_rfc))\n",
        "print(classification_report(y_test, y_pred_rfc))\n",
        "\n",
        "# ROC Curve\n",
        "y_prob_rfc = rfc.predict_proba(X_test)[:,1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob_rfc)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label=f'Random Forest (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# gráfico ROC\n",
        "plt.plot([0,1], [0,1], \"k--\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve - Tree Based Models\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xRqI8cQDsHTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 4) XGBoost (Tree-Based) | Maruan"
      ],
      "metadata": {
        "id": "dlOcrtOzcdv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_xgb = df_cleaned"
      ],
      "metadata": {
        "id": "Sd3G6cfYctdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "bdhpkMUJdtWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover tabelas nao numericas e o target\n",
        "X_xgb = df_xgb.drop(['Date', 'Location', 'RainToday', 'RainTomorrow', 'WindGustDir', 'WindDir9am', 'WindDir3pm'], axis=1)\n",
        "y_xgb = df_xgb['RainTomorrow']\n",
        "\n",
        "# Converter TARGET para numerico\n",
        "le = LabelEncoder()\n",
        "y_xgb = le.fit_transform(y_xgb)"
      ],
      "metadata": {
        "id": "bAVD7f30c9xB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X_xgb, y_xgb, test_size=0.2, random_state=42, stratify=y_xgb)"
      ],
      "metadata": {
        "id": "Htqfd4XGdvut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost model\n",
        "\n",
        "# resultado com parametros padrao: 85.69%\n",
        "xgboost = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "\n",
        "xgboost.fit(X_train_xgb, y_train_xgb)"
      ],
      "metadata": {
        "id": "lnN3QQV6dw1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliacao\n",
        "\n",
        "y_pred_xgb = xgboost.predict(X_test_xgb)\n",
        "accuracy_xgb = accuracy_score(y_test_xgb, y_pred_xgb)\n",
        "\n",
        "print(f\"XGBoost Accuracy: {accuracy_xgb * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "2Dz4aK4pdzq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 5) LightGBM Classifier (Tree-Based) | Maruan"
      ],
      "metadata": {
        "id": "km0x2y5MYfmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_lgbm = df_cleaned"
      ],
      "metadata": {
        "id": "1uWH4ps6ZWm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "-35fzPwTZxL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover tabelas nao numericas e o target\n",
        "X_lgbm = df_lgbm.drop(['Date', 'Location', 'RainToday', 'RainTomorrow', 'WindGustDir', 'WindDir9am', 'WindDir3pm'], axis=1)\n",
        "y_lgbm = df_lgbm['RainTomorrow']\n",
        "\n",
        "# Converter TARGET para numerico\n",
        "le = LabelEncoder()\n",
        "y_lgbm = le.fit_transform(y_lgbm)"
      ],
      "metadata": {
        "id": "hbePQB3HZkmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lgbm, X_test_lgbm, y_train_lgbm, y_test_lgbm = train_test_split(X_lgbm, y_lgbm, test_size=0.2, random_state=42, stratify=y_lgbm)"
      ],
      "metadata": {
        "id": "CsScsIUbZ-Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM model\n",
        "\n",
        "# resultado com parametros padrao: 85.90%\n",
        "# melhor resultado com parametros personalizados: 86.46%\n",
        "lgbm = lgb.LGBMClassifier(\n",
        "    random_state=42,\n",
        "    n_estimators=52783,\n",
        "    learning_rate=0.055,\n",
        "    num_leaves=80,\n",
        "    max_depth=-1,\n",
        "    max_bin=716,\n",
        "    min_data_in_leaf=60,\n",
        "    min_sum_hessian_in_leaf=5.0,\n",
        "    min_gain_to_split=0.01,\n",
        "    feature_fraction=0.8,\n",
        "    bagging_fraction=0.8,\n",
        "    bagging_freq=1,\n",
        "    lambda_l1=0.1,\n",
        "    lambda_l2=2.0,\n",
        "    # extra_trees=True,\n",
        "    # class_weight=\"balanced\",\n",
        "    n_jobs=-1,\n",
        "    verbose=-1 # para nao encher de log no console senao o colab fica com 500mb\n",
        ")\n",
        "\n",
        "lgbm.fit(\n",
        "    X_train_lgbm, y_train_lgbm,\n",
        "    eval_set=[(X_test_lgbm, y_test_lgbm)],\n",
        "    eval_metric=[\"auc\", \"binary_logloss\"],\n",
        "    callbacks=[lgb.early_stopping(100)]\n",
        ")"
      ],
      "metadata": {
        "id": "EhlUSgT9aBNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliacao\n",
        "y_pred_lgbm = lgbm.predict(X_test_lgbm)\n",
        "accuracy_lgbm = accuracy_score(y_test_lgbm, y_pred_lgbm)\n",
        "\n",
        "print(f\"LightGBM Accuracy: {accuracy_lgbm * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "tLLTDSMraGRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 6) CatBoost Classifier (Tree-Based) | Maruan"
      ],
      "metadata": {
        "id": "d-oDwJ0kY2EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_cb = df_cleaned"
      ],
      "metadata": {
        "id": "8i8A3p6fU2Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n",
        "\n",
        "import catboost as cb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "UjQ6oXS1iqpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover tabelas nao numericas e o target\n",
        "X_cb = df_cb.drop(['Date', 'Location', 'RainToday', 'RainTomorrow', 'WindGustDir', 'WindDir9am', 'WindDir3pm'], axis=1)\n",
        "y_cb = df_cb['RainTomorrow']\n",
        "\n",
        "# Converter TARGET para numerico\n",
        "le = LabelEncoder()\n",
        "y_cb = le.fit_transform(y_cb)"
      ],
      "metadata": {
        "id": "UBv-WZTHilmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_cb, X_test_cb, y_train_cb, y_test_cb = train_test_split(X_cb, y_cb, test_size=0.2, random_state=42, stratify=y_cb)"
      ],
      "metadata": {
        "id": "anyvstvBi5jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CatBoost Model\n",
        "\n",
        "# resultado com parametros padrao: 86.46%\n",
        "# melhor resultado com parametros personalizados: 86.37%\n",
        "\n",
        "catboost = cb.CatBoostClassifier(\n",
        "    random_state=40,\n",
        "    # iterations=5000,\n",
        "    # learning_rate=0.1,\n",
        "    # depth=6,\n",
        "    # l2_leaf_reg=3,\n",
        "    # model_size_reg=None,\n",
        "    # colsample_bylevel=0.8,\n",
        "    # loss_function='Logloss',\n",
        "    # eval_metric='Accuracy',\n",
        "    # leaf_estimation_iterations=10,\n",
        "    # bootstrap_type='Bayesian',\n",
        "    # bagging_temperature=0.3,\n",
        "    # random_strength=0.2,\n",
        "    # auto_class_weights=\"Balanced\",\n",
        "    # od_type='Iter',\n",
        "    # od_wait=50,\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "catboost.fit(X_train_cb, y_train_cb)"
      ],
      "metadata": {
        "id": "nvn34geYi5O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliacao\n",
        "y_pred_cb = catboost.predict(X_test_cb)\n",
        "accuracy_cb = accuracy_score(y_test_cb, y_pred_cb)\n",
        "\n",
        "print(f\"CatBoost Accuracy: {accuracy_cb * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "WYS2cq6FjGuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7) Perceptron | Maruan"
      ],
      "metadata": {
        "id": "n0FN07TGhZc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_perceptron = df_cleaned"
      ],
      "metadata": {
        "id": "-tYSgE4qi3h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "iZq1UqvrhbWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover tabelas nao numericas e o target\n",
        "X_perceptron = df_perceptron.drop(['Date', 'Location', 'RainToday', 'RainTomorrow', 'WindGustDir', 'WindDir9am', 'WindDir3pm'], axis=1)\n",
        "y_perceptron = df_perceptron['RainTomorrow']\n",
        "\n",
        "# Converter TARGET para numerico\n",
        "le = LabelEncoder()\n",
        "y_perceptron = le.fit_transform(y_perceptron)"
      ],
      "metadata": {
        "id": "g0Olm00Fi54t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_perceptron, X_test_perceptron, y_train_perceptron, y_test_perceptron = train_test_split(X_perceptron, y_perceptron, test_size=0.2, random_state=42, stratify=y_perceptron)"
      ],
      "metadata": {
        "id": "cNCQutBUi9Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# escalar\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_perceptron = scaler.fit_transform(X_train_perceptron)\n",
        "X_test_scaled_perceptron = scaler.transform(X_test_perceptron)"
      ],
      "metadata": {
        "id": "0oEq1GMEi-Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perceptron model\n",
        "\n",
        "perceptron = Perceptron(random_state=43)\n",
        "\n",
        "perceptron.fit(X_train_scaled_perceptron, y_train_perceptron)"
      ],
      "metadata": {
        "id": "G8PhcNXXjAd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliacao\n",
        "\n",
        "y_pred_perceptron = perceptron.predict(X_test_scaled_perceptron)\n",
        "\n",
        "accuracy_perceptron = accuracy_score(y_test_perceptron, y_pred_perceptron)\n",
        "\n",
        "print(f\"Perceptron Accuracy: {accuracy_perceptron * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "3ibibGGfjB32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 8) Gaussian Naive Bayes (Naive Bayes) Falcão"
      ],
      "metadata": {
        "id": "GRfSI7DrY5EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_gnb = df_cleaned"
      ],
      "metadata": {
        "id": "MmawjMHRU4HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conferir Data"
      ],
      "metadata": {
        "id": "UvyaUPw4tOYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'Date' in df_gnb.columns:\n",
        "    df_gnb = df_gnb.drop(columns=['Date'])"
      ],
      "metadata": {
        "id": "3r35RRbetXhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformar colunas categóricas em números"
      ],
      "metadata": {
        "id": "5hViarq5tlgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for col in df.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "Q5Vi8bR-tuXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### # Separar X e y (ajuste o nome da coluna alvo)"
      ],
      "metadata": {
        "id": "bOqAEWzKt4vF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar X e y (ajuste o nome da coluna alvo)\n",
        "X = df_gnb.drop(columns=['RainTomorrow'])\n",
        "y = df_gnb['RainTomorrow']\n",
        "\n",
        "# Converter variáveis categóricas em variáveis dummy (one-hot encoding)\n",
        "X = pd.get_dummies(X, drop_first=True)"
      ],
      "metadata": {
        "id": "TvVSXqjkt8mD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dividir e treinar"
      ],
      "metadata": {
        "id": "8ko-0OChuCOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar X e y (ajuste o nome da coluna alvo)\n",
        "X = df_gnb.drop(columns=['RainTomorrow']) # Drop the 'Date' column\n",
        "y = df_gnb['RainTomorrow']\n",
        "\n",
        "# Converter variáveis categóricas em variáveis dummy (one-hot encoding)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "mzoV3bF8uHJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Escalonar variáveis"
      ],
      "metadata": {
        "id": "A3pbjCAruKnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Escalonar variáveis\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "NCpNCafZuN_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinar Gaussian Naive Bayes"
      ],
      "metadata": {
        "id": "axxwKrDhuRAS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05c2b09d"
      },
      "source": [
        "# Converter variáveis categóricas em variáveis dummy (one-hot encoding)\n",
        "X = pd.get_dummies(X, drop_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the data is in a suitable format (e.g., NumPy array with float type)\n",
        "X_train = np.asarray(X_train, dtype=np.float64)\n",
        "X_test = np.asarray(X_test, dtype=np.float64)\n",
        "\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6me8pkEGuVNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a6c84fa"
      },
      "source": [
        "print(\"Missing values in X_train after preprocessing:\")\n",
        "print(pd.DataFrame(X_train).isnull().sum().sum())\n",
        "\n",
        "print(\"Missing values in X_test after preprocessing:\")\n",
        "print(pd.DataFrame(X_test).isnull().sum().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avaliar"
      ],
      "metadata": {
        "id": "kKGNNJqQvgQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "y_pred = gnb.predict(X_test)\n",
        "print(f'Acurácia: {accuracy_score(y_test, y_pred):.2f}')\n",
        "print('Relatório de Classificação:')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "PpNEVPSqviLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tentar melhorar a acurácia"
      ],
      "metadata": {
        "id": "f_HtfHP8v1Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from imblearn.over_sampling import SMOTE  # Se tiver classes desbalanceadas\n",
        "\n",
        "# 1. Balancear dados (se necessário)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# 2. Selecionar melhores features (por exemplo as 10 melhores)\n",
        "selector = SelectKBest(f_classif, k=10)\n",
        "X_selected = selector.fit_transform(X_resampled, y_resampled)\n",
        "\n",
        "# 3. Dividir os dados novamente\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_resampled, test_size=0.3, random_state=42)\n",
        "\n",
        "# 4. Escalonar\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 5. Treinar GaussianNB com ajuste var_smoothing\n",
        "gnb = GaussianNB(var_smoothing=1e-9)\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# 6. Avaliar com cross-validation e teste final\n",
        "scores = cross_val_score(gnb, X_train, y_train, cv=5)\n",
        "print(f'Cross-validation accuracy média: {scores.mean():.2f}')\n",
        "\n",
        "y_pred = gnb.predict(X_test)\n",
        "print(f'Acurácia no teste: {accuracy_score(y_test, y_pred):.2f}')\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "Lb2pdngFv87S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 9) Support Vector Classification (SVC) | MC"
      ],
      "metadata": {
        "id": "QPyKuQuPY-dY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_svc = df_cleaned"
      ],
      "metadata": {
        "id": "OHwEH7oEU7AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "mI20AwVshPPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando Features e target\n",
        "X = df_svc.drop(columns=[\n",
        "    'RainTomorrow', 'Date', 'Location',\n",
        "    'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'\n",
        "])\n",
        "y = df_svc['RainTomorrow']"
      ],
      "metadata": {
        "id": "AcjfZSSW3pkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificando Target\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "RCte875K3-62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "DMATIlXS4Esl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalando\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "eXRlGM6G4K6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando svc\n",
        "svc = SVC(kernel='rbf', C=1.0, random_state=42)\n",
        "svc.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "lt5pQhfb5gUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsao\n",
        "y_pred = svc.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "Qkmaj2AT5pBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliacao\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nSVC accuracy score {accuracy:.2f}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nD-he3os53az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 10) Multi-Layer Perceptron (MLPClassifier) |"
      ],
      "metadata": {
        "id": "Bd59Yc6zZA97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_mlp = df_cleaned"
      ],
      "metadata": {
        "id": "MprVRgNYU8XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 11) AdaBoost Classifier (Ensemble Methods) | MC"
      ],
      "metadata": {
        "id": "EvSUMONvZEk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Copia do dataframe\n",
        "df_ada = df_cleaned"
      ],
      "metadata": {
        "id": "0Yf5w6ohU9en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "A64Fb-Jc8Wbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar features e target\n",
        "X = df_ada.drop(columns=[\n",
        "    'RainTomorrow', 'Date', 'Location',\n",
        "    'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'\n",
        "])\n",
        "y = df_ada['RainTomorrow']"
      ],
      "metadata": {
        "id": "Ng8es4458KhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificando Target\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "v-gJSewb8aKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "FygE7Q2o8hg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Escalando\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "oQtM8bnG8ou5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando ada\n",
        "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "ada.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "j1FSlh-F8rYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsao\n",
        "y_pred_ada = ada.predict(X_test_scaled)\n",
        "accuracy_ada = accuracy_score(y_test, y_pred_ada)"
      ],
      "metadata": {
        "id": "wu9u90nz9COY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliacao\n",
        "print(f\"AdaBoost Accuracy: {accuracy_ada * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "OhaQuw5h9JYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 12) Quadratic Discriminant Analysis (QDA) |"
      ],
      "metadata": {
        "id": "NewdDNlKZHZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_qda = df_cleaned"
      ],
      "metadata": {
        "id": "XbT8L3KAU-gS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Comite Classificador:"
      ],
      "metadata": {
        "id": "1Ltqvt78VXXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copia do dataframe\n",
        "df_comittee = df_cleaned"
      ],
      "metadata": {
        "id": "TdzWexFNhGnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "4OVngyrVmjJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab18ab55"
      },
      "source": [
        "# Remover tabelas nao numericas e o target\n",
        "X_committee = df_comittee.drop(['Date', 'Location', 'RainToday', 'RainTomorrow', 'WindGustDir', 'WindDir9am', 'WindDir3pm'], axis=1)\n",
        "y_committee = df_comittee['RainTomorrow']\n",
        "\n",
        "# Converter TARGET para numerico\n",
        "le = LabelEncoder()\n",
        "y_committee = le.fit_transform(y_committee)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mesma coisa dos classifiers mas para o comite\n",
        "X_train_committee, X_test_committee, y_train_committee, y_test_committee = train_test_split(X_committee, y_committee, test_size=0.2, random_state=42, stratify=y_committee)"
      ],
      "metadata": {
        "id": "m-bJJAbliMh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# QUAIS CLASSIFICADORES VAO SER USADOS NO COMITE - QUANDO TERMINAREM UM ALGORITIMO NOVO, COLOCA ELE AQUI !!!!!!!!!!!!!\n",
        "estimators = [('lgbm', lgbm), ('catboost', catboost), ('xgboost', xgboost), ('perceptron', perceptron), ('svc', svc), ('adaboost', ada)]"
      ],
      "metadata": {
        "id": "6BHEsG4-iO4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifiers Comittee\n",
        "\n",
        "# Tipos de voting\n",
        "# 'hard' = maioria\n",
        "# 'soft' usa pesos, weights=[]\n",
        "weights_acc = [accuracy_lgbm, accuracy_cb] # pesos sendo a acurracy de cada modelo\n",
        "\n",
        "committee = VotingClassifier(estimators=estimators, voting='hard')\n",
        "\n",
        "\n",
        "committee.fit(X_train_committee, y_train_committee)"
      ],
      "metadata": {
        "id": "1GAAXoOCiSuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliacao\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# RESULTADOS COM APENAS LightGBM e CatBoost (maruan)\n",
        "# Acurracy com HARD VOTING: 85.97%\n",
        "# Acurracy com SOFT e accuracy dos algoritimos como weights: 85.86%\n",
        "# tentei fazer um grid search pelos melhores pesos mas rodou por 6 horas e crashou\n",
        "# cada vez que eu boto um algoritimo novo fica pior KKKKKKKKKKKKKKKKKKKK\n",
        "\n",
        "accuracy_committee = committee.score(X_test_committee, y_test_committee)\n",
        "y_pred_committee = committee.predict(X_test_committee)\n",
        "accuracyf1_committee = f1_score(y_test_committee, y_pred_committee)\n",
        "\n",
        "\n",
        "print(f\"Classifier Committee Accuracy: {accuracy_committee * 100:.2f}%\")\n",
        "print(f\"Classifier Committee F1-score: {accuracyf1_committee * 100:.2f}%\")\n",
        "\n",
        "print('------------------------------------------')\n",
        "algorithm_names = [name for name, _ in estimators]\n",
        "print(f\"Algoritmos do Comite: {algorithm_names}\")\n"
      ],
      "metadata": {
        "id": "1DkE63ITiafk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#### sugestao de outros algoritimos:\n",
        "\n",
        "\n",
        "*   Logistic Regression\n",
        "*   SGDClassifier\n",
        "*   Passive Aggressive Classifier (nao sei se funcionaria aqui)\n",
        "*   Extra Trees Classifier (tipo um random forest ao quadrado)\n",
        "*   GradientBoostingClassifier\n",
        "*   HistGradientBoostingClassifier (uma versao customizada do XGBoost/LightGBM)\n",
        "*   Linear Discriminant Analysis\n",
        "*   LogitBoost\n",
        "*   Bagged Perceptrons\n",
        "*   AdaBoost com perceptrons dentro\n",
        "\n"
      ],
      "metadata": {
        "id": "jGKmlZkLdGr9"
      }
    }
  ]
}